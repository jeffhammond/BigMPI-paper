% !TEX root = ../bigmpi.tex

\section{Design}
\label{sec:design}

In this section, we describe the mapping from large-count variants
of MPI-like communication functions to MPI-3 functions.
This task usually
involves creating a large-count datatype, but possibly much more.
BigMPI implements all variants of send and receive, blocking and nonblocking variants of
the homogeneous collectives (bcast, gather, scatter, allgather, alltoall)
and RMA (put, get, accumulate, get\_accumulate)
along the lines of the example for MPI\_Send, shown in Figure~\ref{code:mpi_send_x}.
This class of routines provides the most commonly used MPI functionality, 
so for many codes the Forum has been proven correct.  
As we will see in Section~\ref{sec:reductions}, however,
not all parts of the MPI standard were so straightforward.

\begin{figure}
\begin{code}
int MPIX_Send_x(const void *buf, MPI_Count count,
                MPI_Datatype dt, int dest,
                int tag, MPI_Comm comm)
{
    int rc = MPI_SUCCESS;
    if (likely (count <= INT_MAX )) {
        rc = MPI_Send(buf, (int)count, dt, dest, tag, comm);
    } else {
        MPI_Datatype newtype;
        MPIX_Type_contiguous_x(count, dt, &newtype);
        MPI_Type_commit(&newtype);
        rc = MPI_Send(buf, 1, newtype, dest, tag, comm);
        MPI_Type_free(&newtype);
    }
    return rc;
}
\end{code}
\caption{Implementation of large-count Send, which serves as a template
for many other MPI-3 routines.\label{code:mpi_send_x}}
\end{figure}

The critical function in all the large-count implementations noted above
is \texttt{MPIX\_Type\_contiguous\_x}, which emits a single datatype that
represents up to \texttt{SIZE\_MAX} elements.
%Supporting more elements than can fit into $2^{63}$ bytes of memory is
%not necessary, since such a system is unlikely to exist in the foreseeable future.
%However, since we now express these parameters in our own datatypes, we introduce
%a degree of flexibility not currently present in the MPI standard.
This utility routine allows us to implement large-count support in a straightforward
fashion since all instances of $(large\_count,type)$ are mapped to $(1,large\_type)$
by this function.  Figure~\ref{code:type_contig_x} shows our implementation.
An associated decoder function extracts the original $large\_count$ from a
user-defined datatype; this function is employed within the user-defined reduction
operations.  Decoding a datatype is nontrivial even for such a simple case---we
must call \texttt{MPI\_Type\_get\_envelope} and \texttt{MPI\_Type\_get\_contents}
three times each just to unwind the result of \texttt{MPIX\_Type\_contiguous\_x}.
%GWP - do you mean, By hiding these details, BigMPI is a ...? the way you had it, it sounded sounds like MPI does so.
By hiding these details,
BigMPI is a boon to application programmers, the majority of whom are unfamiliar 
with such features in the MPI standard.
%by virtue of hiding these details.

Other datatypes can be supported easily within BigMPI, but this is not a high
priority because the primary goal is to solve the large-count problem for users
who are not currently making use of derived datatypes.
Users who employ derived datatypes in their code already are likely to be able
to implement their own large-count support. 
Nonetheless, the release version of BigMPI will support large-count equivalents
of all the existing datatype constructors.

% split MPI_TYPE_CREATE_STRUCT below on two lines to fix an overfull warning
\begin{figure}
\begin{code}
int MPIX_Type_contiguous_x(MPI_Count count, 
                           MPI_Datatype oldtype, 
                           MPI_Datatype * newtype)
{
    assert(count<SIZE_MAX); /* has to fit into MPI_Aint */
    MPI_Count c = count/INT_MAX, r = count%INT_MAX;

    MPI_Datatype chunks, remainder;
    MPI_Type_vector(c, INT_MAX, INT_MAX, oldtype, &chunks);
    MPI_Type_contiguous(r, oldtype, &remainder);

    MPI_Aint lb /* unused */, extent;
    MPI_Type_get_extent(oldtype, &lb, &extent);

    MPI_Aint remdisp          = (MPI_Aint)c*INT_MAX*extent;
    int blklens[2]            = {1,1};
    MPI_Aint disps[2]         = {0,remdisp};
    MPI_Datatype types[2]     = {chunks,remainder};
    MPI_Type_create_struct(2,
    	blklens, disps, types, newtype);

    MPI_Type_free(&chunks);
    MPI_Type_free(&remainder);

    return MPI_SUCCESS;
}
\end{code}
\caption{Function for construction a large-count contiguous datatype.
A vector type describes a series of adjacent chunks, and a struct type picks up
any remaining data in case the count is not evenly divisible.}
\label{code:type_contig_x}
\end{figure}

%In the general case, MPI\_Type\_create\_struct is required, although BigMPI tries to factorize the count into C integers so we can use MPI\_Type\_vector.

%Ticket 423 would improve user experience because it addresses the common case of large counts of built-ins.

\input{text/reductions}
\input{text/v-collectives}
\input{text/n-collectives}
\input{text/interface}
\input{text/limitations}
\input{text/performance}

