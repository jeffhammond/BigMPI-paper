% !TEX root = ../bigmpi.tex

\subsection{Vector-argument collectives}

Vector-argument collectives (henceforth v-collectives) are the generalization of, 
for example, \texttt{MPI\_Scatter}, \texttt{MPI\_Gather}, and \texttt{MPI\_Alltoall}
when the count but not the datatype varies across processes.
When datatypes are used to support large counts, all  these operations must be
mapped to \texttt{MPI\_Alltoallw} because each large count will be mapped
to a different user-defined datatype, and \texttt{MPI\_Alltoallw} is the only collective
that supports a vector of datatypes.
Using \texttt{MPI\_Alltoallw} to implement, for example, a large-count \texttt{MPI\_Scatterv} is
particularly inefficient because the former assumes inputs from every process,
whereas the latter uses only the input from the root.
However, the overhead of scanning a vector of counts where all but one is zero
is almost certainly inconsequential compared with the cost of transmitting a buffer 
of $2^{31}$ bytes.
%Additionally, such vectors are unlikely to be particularly long since scattering
%a buffer that would run into large-count issues r

%All V-collectives turn into ALLTOALLW because different counts implies different large-count types.

The v-collectives encounter a second, more subtle issue due to the mapping to
\texttt{MPI\_Alltoallw}.  Because this function takes a vector of datatypes, the
displacements into the input and output vectors are given in bytes,
not element count, and the type of this offset is a C integer.
This creates an overflow situation \textit{even 
when the input buffer is less than 2 GiB} because a vector of 1 billion
alternating integers and floats may require an byte offset in excess of $2^{31}$.
Thus, \texttt{MPI\_Alltoallw} is not an acceptable solution for the large-count
v-collectives because of the likelihood of overflowing in the displacement vector.
The use of the  C integer instead of \texttt{MPI\_Aint} for the displacement vector in
the  collective operations added prior to MPI-3 is an unfortunate oversight that
cannot be rectified without breaking backward compatibility.

%ALLTOALLW displacements given in bytes are C int, and therefore it is impossible to offset more than 2GB into the buffer.
%NEIGHBOR\_ALLTOALLW to the rescue?!?!
%MPI\_Neighbor\_alltoallw displacements are MPI\_Aint not int.  This is good.
%Neighborhood collectives require special communicators that must be created for each call (and possibly cached).
%Must allocate new argument vectors and, in the case of alltoall, we wastefully splat the same value in all locations.

Fortunately, the overflow issue with displacements in \texttt{MPI\_Alltoallw} is
resolved by using the neighborhood collectives introduced in MPI-3, which do
use \texttt{MPI\_Aint} for displacements.
On the other hand, neighborhood collectives require an appropriate
communicator, which must be constructed prior to calling \texttt{MPI\_Neighborhood\_alltoallw}.
BigMPI creates a distributed graph communicator using \texttt{MPI\_Dist\_graph\_adjacent}
on the fly for every invocation of the large-count v-collectives, which instead are assumed to incur
insignificant overhead compared with the data movement entailed in such an operation.

Thus, the implementation of large-count v-collectives using \texttt{MPI\_Neighborhood\_alltoallw} 
requires two $O(n_{proc})$ setup steps. The first allocates and populates the vectors of 
send and receive counts, displacements, and datatypes. 
The second creates a distributed graph communicator.
Figures~\ref{code:BigMPI_Convert_vectors} and~\ref{code:BigMPI_Create_graph_comm}
show the implementation of these functions, which are included in their entirety to illustrate that
although the mapping from v-collectives to \texttt{MPI\_Neighborhood\_alltoallw} is feasible,
it is rather involved and in some cases unnatural.
Creating the vector of datatypes requires $O(n_{proc})$ calls to \texttt{BigMPI\_Type\_contiguous\_x},
which itself requires six MPI calls, although all of these are expected to be inexpensive.

% V-collectives using P2P and RMA
%One can follow the definition in MPI to implement all of the V-collectives using P2P.
%RMA (with win\_fence synchronization) also works for the V-collectives.
%Allgatherv using nproc calls to Bcast also works.
%Large-count definitely outside of recursive doubling regime so little to optimize...

An alternative approach to implementing large-count v-collectives is to map
these to point-to-point operations, although this works only for blocking operations
because of the inability to aggregate requests, as described above.
Since large-count v-collectives are well outside the regime where latency-oriented 
optimizations such as recursive-doubling are important, this approach is unlikely to have a significant impact 
on performance, and it eliminates the need for some of the $O(n_{proc})$ setup steps.
The MPI standard describes every collective in terms of its implementation 
in terms of send-recv calls; the point-to-point BigMPI implementation 
follows these recipes closely:
(1) nonblocking receives are preposted by the root or all ranks as appropriate;
(2) the root or all ranks then call nonblocking send; 
and (3) all ranks then call Waitall.
Since the large-count BigMPI send-recv functions are used, there is no need for
$O(n_{proc})$ vectors of datatypes, and so forth---only a vector of \texttt{MPI\_Request}
objects for the nonblocking operations is required.

A third implementation of v-collectives is to use RMA (one-sided) that follows
the same traffic pattern as the point-to-point implementation.
In this case, an MPI window must be created associated with the source (target)
buffers and \texttt{MPI\_Get} (\texttt{MPI\_Put}) operations used for moving data.
The most appropriate synchronization mode for mapping collectives to RMA
is \texttt{MPI\_Win\_fence}, although one could use a passive target instead.
If a future version of the MPI standard introduces a nonblocking
equivalent of \texttt{MPI\_Win\_fence} or \texttt{MPI\_Win\_unlock\_all}, these
could be used to implement nonblocking v-collectives in terms of RMA; 
at least within MPI-3, we are limited to the blocking case.
The RMA implementation was prototyped in BigMPI but is not currently implemented.
%because no performance benefit of one-sided is expected because of the current state
The current state of RMA implementations map one-sided operations to two-sided ones internally. Thus we would expect to see no performance benefit from BigMPI's RMA approach.
If RMA operations exploit RDMA hardware, 
however, noticeable performance improvements may be
observed.

While not named as such, \texttt{MPI\_Reduce\_scatter} is a v-collective.
BigMPI currently does not yet support this function,
but it is straightforward to implement in terms of  \texttt{MPI\_Reduce} and
\texttt{MPI\_Scatterv}, which will be the basis for the BigMPI implementation.

% V-collectives - nonblocking issues

%None of the aforementioned solutions works for nonblocking because:
%What request do we return in the case of P2P or RMA?
%Cannot free argument vectors until complete.
%Any solution involving generalized requests is untenable for users.  BigMPI might use it.

Unfortunately, nonblocking v-collectives cannot be implemented by using the aforementioned approaches.
In the case of the neighborhood collective
implementation, we cannot free the vector temporaries holding the counts,
displacements, and datatypes until the operation has completed.
If callback functions associated with request completion were present in the
MPI standard (see \cite{ticket26} for a proposal of this), then it would
be possible to free the temporary buffers using this callback.
Since one cannot associate a single request with multiple
nonblocking operations, the point-to-point implementation is not viable
for the nonblocking v-collectives.
Moreover, all relevant forms of MPI RMA synchronization have blocking semantics
and thus cannot be used to implement nonblocking collectives.

\textit{We identify nonblocking v-collectives as the second example
where MPI-3 lacks the necessary features to support large counts.}

\begin{figure}
\begin{code}
void BigMPI_Convert_vectors(int num,
                            int splat_old_count,
                            const MPI_Count oldcount,
                            const MPI_Count oldcounts[],
                            int splat_old_type,
                            const MPI_Datatype oldtype,
                            const MPI_Datatype oldtypes[],
                            int zero_new_displs,
                            const MPI_Aint olddispls[],
                            int newcounts[],
                            MPI_Datatype newtypes[],
                            MPI_Aint newdispls[])
{
    assert(splat_old_count || (oldcounts!=NULL));
    assert(splat_old_type  || (oldtypes!=NULL));
    assert(zero_new_displs || (olddispls!=NULL));

    MPI_Aint lb /* unused */, oldextent;
    if (splat_old_type) {
        MPI_Type_get_extent(oldtype, &lb, &oldextent);
    } else {
        /* !splat_old_type implies ALLTOALLW, 
            which implies no displacement zeroing. */
        assert(!zero_new_displs);
    }

    for (int i=0; i<num; i++) {
        /* counts */
        newcounts[i] = 1;

        /* types */
        MPIX_Type_contiguous_x(oldcounts[i], 
                       splat_old_type ? oldtype : oldtypes[i], 
                       &newtypes[i]);
        MPI_Type_commit(&newtypes[i]);

        /* displacements */
        MPI_Aint newextent;
        /* If we are not splatting old type, it implies 
         *  ALLTOALLW, which does not scale the 
         * displacement by the type extent,
         * nor would we ever zero the displacements. */
        if (splat_old_type) {
            MPI_Type_get_extent(newtypes[i], &lb, &newextent);
            newdispls[i] = (zero_new_displs ? 0 : 
                            olddispls[i]*oldextent/newextent);
        } else {
            newdispls[i] = olddispls[i];
        }
    }
    return;
}
\end{code}
\caption{Function for populating the vector inputs 
for \texttt{MPI\_Neighborhood\_alltoallw} for the various v-collectives.}
\label{code:BigMPI_Convert_vectors}
\end{figure}

\begin{figure}
\begin{code}
int BigMPI_Create_graph_comm(MPI_Comm comm_old, int root, 
                             MPI_Comm * comm_dist_graph)
{
    int rank, size;
    MPI_Comm_rank(comm_old, &rank);
    MPI_Comm_size(comm_old, &size);

    /* in the all case (root == -1), every rank is a 
     * destination for every other rank;
     * otherwise, only the root is a destination. */
    int indeg  = (root == -1 || root==rank) ? size : 0;
    /* in the all case (root == -1), every rank is a 
     * source for every other rank;
     * otherwise, all non-root processes are the 
     * source for only one rank (the root). */
    int outdeg = (root == -1 || root==rank) ? size : 1;

    int * srcs = malloc(indegree*sizeof(int));  
    assert(srcs!=NULL);
    int * dsts = malloc(outdegree*sizeof(int)); 
    assert(dsts!=NULL);

    for (int i=0; i<indegree; i++) {
        srcs[i] = i;
    }
    for (int i=0; i<outdegree; i++) {
        dsts[i] = (root == -1 || root==rank) ? i : root;
    }

    int empty = MPI_WEIGHTS_EMPTY;
    int unwtd = MPI_UNWEIGHTED;
    int rc = MPI_Dist_graph_create_adjacent(comm_old,
                indeg, srcs, indeg==0 ? empty : unwtd,
                outdeg, dsts, outdeg==0 ? empty : unwtd,
                MPI_INFO_NULL, 0 /* reorder */, 
                comm_dist_graph);

    free(srcs);
    free(dsts);

    return rc;
}
\end{code}
\caption{Function for constructing the distributed graph communicator
that allows the mapping of both rooted (e.g. \texttt{MPI\_Gatherv}) and
non-rooted (e.g. \texttt{MPI\_Allgatherv}) collectives to
\texttt{MPI\_Neighborhood\_alltoallw}.}
\label{code:BigMPI_Create_graph_comm}
\end{figure}
